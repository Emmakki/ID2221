{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdSDlivzQnP_"
      },
      "source": [
        "# Install Java"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gytL-E1XQjsT"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install openjdk-11-jdk -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!java -version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!readlink -f $(which java)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlP0pRv-Q5fA"
      },
      "source": [
        "# Install HBase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6diX-x1Q7wi"
      },
      "outputs": [],
      "source": [
        "!wget https://downloads.apache.org/hbase/2.5.10/hbase-2.5.10-bin.tar.gz\n",
        "!tar xvf hbase-2.5.10-bin.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QfkzaAZRSgTd"
      },
      "outputs": [],
      "source": [
        "! mv hbase-2.5.10 /opt/hbase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VkA1WSGaSU7v"
      },
      "outputs": [],
      "source": [
        "!sed -i 's|# export JAVA_HOME=.*|export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64|' /opt/hbase/conf/hbase-env.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "openjdk version \"11.0.24\" 2024-07-16\n",
            "OpenJDK Runtime Environment (build 11.0.24+8-post-Ubuntu-1ubuntu324.04.1)\n",
            "OpenJDK 64-Bit Server VM (build 11.0.24+8-post-Ubuntu-1ubuntu324.04.1, mixed mode, sharing)\n"
          ]
        }
      ],
      "source": [
        "# Verify JAVA_HOME\n",
        "import os\n",
        "\n",
        "# Check if JAVA_HOME is set, if not set it to the correct path\n",
        "java_home = '/usr/lib/jvm/java-11-openjdk-amd64'\n",
        "if not os.path.exists(java_home):\n",
        "    raise FileNotFoundError(f'Java path not found: {java_home}')\n",
        "os.environ['JAVA_HOME'] = java_home\n",
        "os.environ['PATH'] = java_home + '/bin:' + os.environ['PATH']\n",
        "\n",
        "\n",
        "!java -version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgjj1OgYSoay",
        "outputId": "a24bcb61-8431-469d-f49a-4bac229782d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "running master, logging to /opt/hbase/bin/../logs/hbase-emma-master-emma-Inspiron-3501.out\n"
          ]
        }
      ],
      "source": [
        "#Start HBase\n",
        "!/opt/hbase/bin/start-hbase.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvzRQAdsS1Io",
        "outputId": "2578b959-319a-46a4-c5fd-065b4544db36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "385472 Jps\n",
            "385096 HMaster\n"
          ]
        }
      ],
      "source": [
        "!jps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5mLrlaUU9HJ"
      },
      "source": [
        "# Install Spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEwy7ngLU_2V"
      },
      "outputs": [],
      "source": [
        "!wget -v https://dlcdn.apache.org/spark/spark-3.4.3/spark-3.4.3-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-Ehg8VwVYaQ"
      },
      "outputs": [],
      "source": [
        "!tar xvf spark-3.4.3-bin-hadoop3.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3FDtegtVjjA"
      },
      "outputs": [],
      "source": [
        "!pip3 install findspark --break-system-packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! mv spark-3.4.3-bin-hadoop3 /opt/spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Karo_bC2VkeI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import findspark\n",
        "\n",
        "os.environ[\"SPARK_HOME\"] = \"/opt/spark\"\n",
        "\n",
        "# Initialize PySpark\n",
        "findspark.init()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49iKscI-TLmX"
      },
      "source": [
        "# Collect data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0Jm1N1AWz4k"
      },
      "source": [
        "Download csv file from https://obis.org/data/access/#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!echo \"create 'OBIS', 'cf'\" | /opt/hbase/bin/hbase shell"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "24/09/24 12:02:17 WARN Utils: Your hostname, emma-Inspiron-3501 resolves to a loopback address: 127.0.1.1; using 193.10.38.136 instead (on interface wlp0s20f3)\n",
            "24/09/24 12:02:17 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ":: loading settings :: url = jar:file:/opt/spark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Ivy Default Cache set to: /home/emma/.ivy2/cache\n",
            "The jars for the packages stored in: /home/emma/.ivy2/jars\n",
            "org.apache.hbase.connectors.spark#hbase-spark added as a dependency\n",
            ":: resolving dependencies :: org.apache.spark#spark-submit-parent-f9cdd4e1-cb3b-4295-9233-109f0610d892;1.0\n",
            "\tconfs: [default]\n",
            "\tfound org.apache.hbase.connectors.spark#hbase-spark;1.0.1 in central\n",
            "\tfound org.slf4j#slf4j-api;1.7.36 in central\n",
            "\tfound org.apache.hbase.thirdparty#hbase-shaded-miscellaneous;4.1.4 in central\n",
            "\tfound com.google.errorprone#error_prone_annotations;2.18.0 in central\n",
            "\tfound org.apache.hbase#hbase-shaded-client;2.5.4 in central\n",
            "\tfound io.opentelemetry#opentelemetry-semconv;1.15.0-alpha in central\n",
            "\tfound io.opentelemetry#opentelemetry-api;1.15.0 in central\n",
            "\tfound io.opentelemetry#opentelemetry-context;1.15.0 in central\n",
            "\tfound commons-logging#commons-logging;1.2 in central\n",
            "\tfound org.apache.htrace#htrace-core4;4.1.0-incubating in central\n",
            "\tfound org.apache.yetus#audience-annotations;0.5.0 in central\n",
            "\tfound org.apache.hbase.connectors.spark#hbase-spark-protocol-shaded;1.0.1 in central\n",
            "\tfound org.apache.hbase.thirdparty#hbase-shaded-protobuf;4.1.4 in central\n",
            "\tfound org.apache.hbase#hbase-shaded-mapreduce;2.5.4 in central\n",
            "\tfound jakarta.annotation#jakarta.annotation-api;1.3.5 in central\n",
            "\tfound jakarta.validation#jakarta.validation-api;2.0.2 in central\n",
            "\tfound org.glassfish.hk2.external#jakarta.inject;2.6.1 in central\n",
            "\tfound org.javassist#javassist;3.25.0-GA in central\n",
            "\tfound org.apache.hadoop#hadoop-distcp;2.10.2 in central\n",
            "\tfound org.apache.hadoop#hadoop-annotations;2.10.2 in central\n",
            "\tfound org.apache.avro#avro;1.7.7 in central\n",
            "\tfound org.codehaus.jackson#jackson-core-asl;1.9.13 in central\n",
            "\tfound org.codehaus.jackson#jackson-mapper-asl;1.9.13 in central\n",
            "\tfound org.xerial.snappy#snappy-java;1.0.5 in central\n",
            "\tfound org.apache.commons#commons-compress;1.4.1 in central\n",
            "\tfound org.tukaani#xz;1.0 in central\n",
            "\tfound org.scala-lang#scala-reflect;2.12.15 in central\n",
            "\tfound org.apache.hadoop#hadoop-client;3.2.4 in central\n",
            "\tfound org.apache.hadoop#hadoop-common;3.2.4 in central\n",
            "\tfound org.apache.hadoop#hadoop-annotations;3.2.4 in central\n",
            "\tfound com.google.guava#guava;27.0-jre in central\n",
            "\tfound com.google.guava#failureaccess;1.0 in central\n",
            "\tfound com.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava in central\n",
            "\tfound com.google.code.findbugs#jsr305;3.0.2 in central\n",
            "\tfound org.checkerframework#checker-qual;2.5.2 in central\n",
            "\tfound com.google.j2objc#j2objc-annotations;1.1 in central\n",
            "\tfound org.codehaus.mojo#animal-sniffer-annotations;1.17 in central\n",
            "\tfound commons-cli#commons-cli;1.2 in central\n",
            "\tfound org.apache.commons#commons-math3;3.1.1 in central\n",
            "\tfound org.apache.httpcomponents#httpclient;4.5.13 in central\n",
            "\tfound org.apache.httpcomponents#httpcore;4.4.13 in central\n",
            "\tfound commons-codec#commons-codec;1.11 in central\n",
            "\tfound commons-io#commons-io;2.11.0 in central\n",
            "\tfound commons-net#commons-net;3.6 in central\n",
            "\tfound commons-collections#commons-collections;3.2.2 in central\n",
            "\tfound javax.servlet#javax.servlet-api;3.1.0 in central\n",
            "\tfound org.eclipse.jetty#jetty-server;9.4.43.v20210629 in central\n",
            "\tfound org.eclipse.jetty#jetty-http;9.4.43.v20210629 in central\n",
            "\tfound org.eclipse.jetty#jetty-util;9.4.43.v20210629 in central\n",
            "\tfound org.eclipse.jetty#jetty-io;9.4.43.v20210629 in central\n",
            "\tfound org.eclipse.jetty#jetty-servlet;9.4.43.v20210629 in central\n",
            "\tfound org.eclipse.jetty#jetty-security;9.4.43.v20210629 in central\n",
            "\tfound org.eclipse.jetty#jetty-util-ajax;9.4.43.v20210629 in central\n",
            "\tfound org.eclipse.jetty#jetty-webapp;9.4.43.v20210629 in central\n",
            "\tfound org.eclipse.jetty#jetty-xml;9.4.43.v20210629 in central\n",
            "\tfound com.sun.jersey#jersey-core;1.19 in central\n",
            "\tfound javax.ws.rs#jsr311-api;1.1.1 in central\n",
            "\tfound com.sun.jersey#jersey-servlet;1.19 in central\n",
            "\tfound com.sun.jersey#jersey-server;1.19 in central\n",
            "\tfound com.sun.jersey#jersey-json;1.19 in central\n",
            "\tfound org.codehaus.jettison#jettison;1.1 in central\n",
            "\tfound com.sun.xml.bind#jaxb-impl;2.2.3-1 in central\n",
            "\tfound javax.xml.bind#jaxb-api;2.2.11 in central\n",
            "\tfound org.codehaus.jackson#jackson-jaxrs;1.9.13 in central\n",
            "\tfound org.codehaus.jackson#jackson-xc;1.9.13 in central\n",
            "\tfound ch.qos.reload4j#reload4j;1.2.25 in central\n",
            "\tfound commons-beanutils#commons-beanutils;1.9.4 in central\n",
            "\tfound org.apache.commons#commons-configuration2;2.1.1 in central\n",
            "\tfound org.apache.commons#commons-lang3;3.12.0 in central\n",
            "\tfound org.apache.commons#commons-text;1.4 in central\n",
            "\tfound org.slf4j#slf4j-reload4j;1.7.35 in central\n",
            "\tfound com.google.re2j#re2j;1.1 in central\n",
            "\tfound com.google.protobuf#protobuf-java;2.5.0 in central\n",
            "\tfound com.google.code.gson#gson;2.9.0 in central\n",
            "\tfound org.apache.hadoop#hadoop-auth;3.2.4 in central\n",
            "\tfound com.nimbusds#nimbus-jose-jwt;9.8.1 in central\n",
            "\tfound com.github.stephenc.jcip#jcip-annotations;1.0-1 in central\n",
            "\tfound net.minidev#json-smart;2.4.7 in central\n",
            "\tfound net.minidev#accessors-smart;2.4.7 in central\n",
            "\tfound org.ow2.asm#asm;5.0.4 in central\n",
            "\tfound org.apache.zookeeper#zookeeper;3.4.14 in central\n",
            "\tfound com.github.spotbugs#spotbugs-annotations;3.1.9 in central\n",
            "\tfound io.netty#netty;3.10.6.Final in central\n",
            "\tfound org.apache.curator#curator-framework;2.13.0 in central\n",
            "\tfound org.apache.curator#curator-client;2.13.0 in central\n",
            "\tfound org.apache.kerby#kerb-simplekdc;1.0.1 in central\n",
            "\tfound org.apache.kerby#kerb-client;1.0.1 in central\n",
            "\tfound org.apache.kerby#kerby-config;1.0.1 in central\n",
            "\tfound org.apache.kerby#kerb-core;1.0.1 in central\n",
            "\tfound org.apache.kerby#kerby-pkix;1.0.1 in central\n",
            "\tfound org.apache.kerby#kerby-asn1;1.0.1 in central\n",
            "\tfound org.apache.kerby#kerby-util;1.0.1 in central\n",
            "\tfound org.apache.kerby#kerb-common;1.0.1 in central\n",
            "\tfound org.apache.kerby#kerb-crypto;1.0.1 in central\n",
            "\tfound org.apache.kerby#kerb-util;1.0.1 in central\n",
            "\tfound org.apache.kerby#token-provider;1.0.1 in central\n",
            "\tfound org.apache.kerby#kerb-admin;1.0.1 in central\n",
            "\tfound org.apache.kerby#kerb-server;1.0.1 in central\n",
            "\tfound org.apache.kerby#kerb-identity;1.0.1 in central\n",
            "\tfound org.apache.kerby#kerby-xdr;1.0.1 in central\n",
            "\tfound com.jcraft#jsch;0.1.55 in central\n",
            "\tfound org.apache.curator#curator-recipes;2.13.0 in central\n",
            "\tfound org.apache.commons#commons-compress;1.21 in central\n",
            "\tfound com.fasterxml.jackson.core#jackson-databind;2.10.5.1 in central\n",
            "\tfound com.fasterxml.jackson.core#jackson-annotations;2.10.5 in central\n",
            "\tfound com.fasterxml.jackson.core#jackson-core;2.10.5 in central\n",
            "\tfound org.codehaus.woodstox#stax2-api;4.2.1 in central\n",
            "\tfound com.fasterxml.woodstox#woodstox-core;5.3.0 in central\n",
            "\tfound dnsjava#dnsjava;2.1.7 in central\n",
            "\tfound javax.activation#javax.activation-api;1.2.0 in central\n",
            "\tfound javax.servlet.jsp#jsp-api;2.1 in central\n",
            "\tfound jline#jline;0.9.94 in central\n",
            "\tfound org.apache.hadoop#hadoop-hdfs-client;3.2.4 in central\n",
            "\tfound com.squareup.okhttp#okhttp;2.7.5 in central\n",
            "\tfound com.squareup.okio#okio;1.6.0 in central\n",
            "\tfound org.apache.hadoop#hadoop-yarn-api;3.2.4 in central\n",
            "\tfound org.apache.hadoop#hadoop-yarn-client;3.2.4 in central\n",
            "\tfound org.apache.hadoop#hadoop-mapreduce-client-core;3.2.4 in central\n",
            "\tfound org.apache.hadoop#hadoop-yarn-common;3.2.4 in central\n",
            "\tfound com.sun.jersey#jersey-client;1.19 in central\n",
            "\tfound com.fasterxml.jackson.module#jackson-module-jaxb-annotations;2.10.5 in central\n",
            "\tfound jakarta.xml.bind#jakarta.xml.bind-api;2.3.2 in central\n",
            "\tfound jakarta.activation#jakarta.activation-api;1.2.1 in central\n",
            "\tfound com.fasterxml.jackson.jaxrs#jackson-jaxrs-json-provider;2.10.5 in central\n",
            "\tfound com.fasterxml.jackson.jaxrs#jackson-jaxrs-base;2.10.5 in central\n",
            "\tfound org.apache.hadoop#hadoop-mapreduce-client-jobclient;3.2.4 in central\n",
            "\tfound org.apache.hadoop#hadoop-mapreduce-client-common;3.2.4 in central\n",
            "\tfound com.google.inject#guice;4.0 in central\n",
            "\tfound javax.inject#javax.inject;1 in central\n",
            "\tfound aopalliance#aopalliance;1.0 in central\n",
            "\tfound com.sun.jersey.contribs#jersey-guice;1.19 in central\n",
            ":: resolution report :: resolve 2152ms :: artifacts dl 77ms\n",
            "\t:: modules in use:\n",
            "\taopalliance#aopalliance;1.0 from central in [default]\n",
            "\tch.qos.reload4j#reload4j;1.2.25 from central in [default]\n",
            "\tcom.fasterxml.jackson.core#jackson-annotations;2.10.5 from central in [default]\n",
            "\tcom.fasterxml.jackson.core#jackson-core;2.10.5 from central in [default]\n",
            "\tcom.fasterxml.jackson.core#jackson-databind;2.10.5.1 from central in [default]\n",
            "\tcom.fasterxml.jackson.jaxrs#jackson-jaxrs-base;2.10.5 from central in [default]\n",
            "\tcom.fasterxml.jackson.jaxrs#jackson-jaxrs-json-provider;2.10.5 from central in [default]\n",
            "\tcom.fasterxml.jackson.module#jackson-module-jaxb-annotations;2.10.5 from central in [default]\n",
            "\tcom.fasterxml.woodstox#woodstox-core;5.3.0 from central in [default]\n",
            "\tcom.github.spotbugs#spotbugs-annotations;3.1.9 from central in [default]\n",
            "\tcom.github.stephenc.jcip#jcip-annotations;1.0-1 from central in [default]\n",
            "\tcom.google.code.findbugs#jsr305;3.0.2 from central in [default]\n",
            "\tcom.google.code.gson#gson;2.9.0 from central in [default]\n",
            "\tcom.google.errorprone#error_prone_annotations;2.18.0 from central in [default]\n",
            "\tcom.google.guava#failureaccess;1.0 from central in [default]\n",
            "\tcom.google.guava#guava;27.0-jre from central in [default]\n",
            "\tcom.google.guava#listenablefuture;9999.0-empty-to-avoid-conflict-with-guava from central in [default]\n",
            "\tcom.google.inject#guice;4.0 from central in [default]\n",
            "\tcom.google.j2objc#j2objc-annotations;1.1 from central in [default]\n",
            "\tcom.google.protobuf#protobuf-java;2.5.0 from central in [default]\n",
            "\tcom.google.re2j#re2j;1.1 from central in [default]\n",
            "\tcom.jcraft#jsch;0.1.55 from central in [default]\n",
            "\tcom.nimbusds#nimbus-jose-jwt;9.8.1 from central in [default]\n",
            "\tcom.squareup.okhttp#okhttp;2.7.5 from central in [default]\n",
            "\tcom.squareup.okio#okio;1.6.0 from central in [default]\n",
            "\tcom.sun.jersey#jersey-client;1.19 from central in [default]\n",
            "\tcom.sun.jersey#jersey-core;1.19 from central in [default]\n",
            "\tcom.sun.jersey#jersey-json;1.19 from central in [default]\n",
            "\tcom.sun.jersey#jersey-server;1.19 from central in [default]\n",
            "\tcom.sun.jersey#jersey-servlet;1.19 from central in [default]\n",
            "\tcom.sun.jersey.contribs#jersey-guice;1.19 from central in [default]\n",
            "\tcom.sun.xml.bind#jaxb-impl;2.2.3-1 from central in [default]\n",
            "\tcommons-beanutils#commons-beanutils;1.9.4 from central in [default]\n",
            "\tcommons-cli#commons-cli;1.2 from central in [default]\n",
            "\tcommons-codec#commons-codec;1.11 from central in [default]\n",
            "\tcommons-collections#commons-collections;3.2.2 from central in [default]\n",
            "\tcommons-io#commons-io;2.11.0 from central in [default]\n",
            "\tcommons-logging#commons-logging;1.2 from central in [default]\n",
            "\tcommons-net#commons-net;3.6 from central in [default]\n",
            "\tdnsjava#dnsjava;2.1.7 from central in [default]\n",
            "\tio.netty#netty;3.10.6.Final from central in [default]\n",
            "\tio.opentelemetry#opentelemetry-api;1.15.0 from central in [default]\n",
            "\tio.opentelemetry#opentelemetry-context;1.15.0 from central in [default]\n",
            "\tio.opentelemetry#opentelemetry-semconv;1.15.0-alpha from central in [default]\n",
            "\tjakarta.activation#jakarta.activation-api;1.2.1 from central in [default]\n",
            "\tjakarta.annotation#jakarta.annotation-api;1.3.5 from central in [default]\n",
            "\tjakarta.validation#jakarta.validation-api;2.0.2 from central in [default]\n",
            "\tjakarta.xml.bind#jakarta.xml.bind-api;2.3.2 from central in [default]\n",
            "\tjavax.activation#javax.activation-api;1.2.0 from central in [default]\n",
            "\tjavax.inject#javax.inject;1 from central in [default]\n",
            "\tjavax.servlet#javax.servlet-api;3.1.0 from central in [default]\n",
            "\tjavax.servlet.jsp#jsp-api;2.1 from central in [default]\n",
            "\tjavax.ws.rs#jsr311-api;1.1.1 from central in [default]\n",
            "\tjavax.xml.bind#jaxb-api;2.2.11 from central in [default]\n",
            "\tjline#jline;0.9.94 from central in [default]\n",
            "\tnet.minidev#accessors-smart;2.4.7 from central in [default]\n",
            "\tnet.minidev#json-smart;2.4.7 from central in [default]\n",
            "\torg.apache.avro#avro;1.7.7 from central in [default]\n",
            "\torg.apache.commons#commons-compress;1.21 from central in [default]\n",
            "\torg.apache.commons#commons-configuration2;2.1.1 from central in [default]\n",
            "\torg.apache.commons#commons-lang3;3.12.0 from central in [default]\n",
            "\torg.apache.commons#commons-math3;3.1.1 from central in [default]\n",
            "\torg.apache.commons#commons-text;1.4 from central in [default]\n",
            "\torg.apache.curator#curator-client;2.13.0 from central in [default]\n",
            "\torg.apache.curator#curator-framework;2.13.0 from central in [default]\n",
            "\torg.apache.curator#curator-recipes;2.13.0 from central in [default]\n",
            "\torg.apache.hadoop#hadoop-annotations;3.2.4 from central in [default]\n",
            "\torg.apache.hadoop#hadoop-auth;3.2.4 from central in [default]\n",
            "\torg.apache.hadoop#hadoop-client;3.2.4 from central in [default]\n",
            "\torg.apache.hadoop#hadoop-common;3.2.4 from central in [default]\n",
            "\torg.apache.hadoop#hadoop-distcp;2.10.2 from central in [default]\n",
            "\torg.apache.hadoop#hadoop-hdfs-client;3.2.4 from central in [default]\n",
            "\torg.apache.hadoop#hadoop-mapreduce-client-common;3.2.4 from central in [default]\n",
            "\torg.apache.hadoop#hadoop-mapreduce-client-core;3.2.4 from central in [default]\n",
            "\torg.apache.hadoop#hadoop-mapreduce-client-jobclient;3.2.4 from central in [default]\n",
            "\torg.apache.hadoop#hadoop-yarn-api;3.2.4 from central in [default]\n",
            "\torg.apache.hadoop#hadoop-yarn-client;3.2.4 from central in [default]\n",
            "\torg.apache.hadoop#hadoop-yarn-common;3.2.4 from central in [default]\n",
            "\torg.apache.hbase#hbase-shaded-client;2.5.4 from central in [default]\n",
            "\torg.apache.hbase#hbase-shaded-mapreduce;2.5.4 from central in [default]\n",
            "\torg.apache.hbase.connectors.spark#hbase-spark;1.0.1 from central in [default]\n",
            "\torg.apache.hbase.connectors.spark#hbase-spark-protocol-shaded;1.0.1 from central in [default]\n",
            "\torg.apache.hbase.thirdparty#hbase-shaded-miscellaneous;4.1.4 from central in [default]\n",
            "\torg.apache.hbase.thirdparty#hbase-shaded-protobuf;4.1.4 from central in [default]\n",
            "\torg.apache.htrace#htrace-core4;4.1.0-incubating from central in [default]\n",
            "\torg.apache.httpcomponents#httpclient;4.5.13 from central in [default]\n",
            "\torg.apache.httpcomponents#httpcore;4.4.13 from central in [default]\n",
            "\torg.apache.kerby#kerb-admin;1.0.1 from central in [default]\n",
            "\torg.apache.kerby#kerb-client;1.0.1 from central in [default]\n",
            "\torg.apache.kerby#kerb-common;1.0.1 from central in [default]\n",
            "\torg.apache.kerby#kerb-core;1.0.1 from central in [default]\n",
            "\torg.apache.kerby#kerb-crypto;1.0.1 from central in [default]\n",
            "\torg.apache.kerby#kerb-identity;1.0.1 from central in [default]\n",
            "\torg.apache.kerby#kerb-server;1.0.1 from central in [default]\n",
            "\torg.apache.kerby#kerb-simplekdc;1.0.1 from central in [default]\n",
            "\torg.apache.kerby#kerb-util;1.0.1 from central in [default]\n",
            "\torg.apache.kerby#kerby-asn1;1.0.1 from central in [default]\n",
            "\torg.apache.kerby#kerby-config;1.0.1 from central in [default]\n",
            "\torg.apache.kerby#kerby-pkix;1.0.1 from central in [default]\n",
            "\torg.apache.kerby#kerby-util;1.0.1 from central in [default]\n",
            "\torg.apache.kerby#kerby-xdr;1.0.1 from central in [default]\n",
            "\torg.apache.kerby#token-provider;1.0.1 from central in [default]\n",
            "\torg.apache.yetus#audience-annotations;0.5.0 from central in [default]\n",
            "\torg.apache.zookeeper#zookeeper;3.4.14 from central in [default]\n",
            "\torg.checkerframework#checker-qual;2.5.2 from central in [default]\n",
            "\torg.codehaus.jackson#jackson-core-asl;1.9.13 from central in [default]\n",
            "\torg.codehaus.jackson#jackson-jaxrs;1.9.13 from central in [default]\n",
            "\torg.codehaus.jackson#jackson-mapper-asl;1.9.13 from central in [default]\n",
            "\torg.codehaus.jackson#jackson-xc;1.9.13 from central in [default]\n",
            "\torg.codehaus.jettison#jettison;1.1 from central in [default]\n",
            "\torg.codehaus.mojo#animal-sniffer-annotations;1.17 from central in [default]\n",
            "\torg.codehaus.woodstox#stax2-api;4.2.1 from central in [default]\n",
            "\torg.eclipse.jetty#jetty-http;9.4.43.v20210629 from central in [default]\n",
            "\torg.eclipse.jetty#jetty-io;9.4.43.v20210629 from central in [default]\n",
            "\torg.eclipse.jetty#jetty-security;9.4.43.v20210629 from central in [default]\n",
            "\torg.eclipse.jetty#jetty-server;9.4.43.v20210629 from central in [default]\n",
            "\torg.eclipse.jetty#jetty-servlet;9.4.43.v20210629 from central in [default]\n",
            "\torg.eclipse.jetty#jetty-util;9.4.43.v20210629 from central in [default]\n",
            "\torg.eclipse.jetty#jetty-util-ajax;9.4.43.v20210629 from central in [default]\n",
            "\torg.eclipse.jetty#jetty-webapp;9.4.43.v20210629 from central in [default]\n",
            "\torg.eclipse.jetty#jetty-xml;9.4.43.v20210629 from central in [default]\n",
            "\torg.glassfish.hk2.external#jakarta.inject;2.6.1 from central in [default]\n",
            "\torg.javassist#javassist;3.25.0-GA from central in [default]\n",
            "\torg.ow2.asm#asm;5.0.4 from central in [default]\n",
            "\torg.scala-lang#scala-reflect;2.12.15 from central in [default]\n",
            "\torg.slf4j#slf4j-api;1.7.36 from central in [default]\n",
            "\torg.slf4j#slf4j-reload4j;1.7.35 from central in [default]\n",
            "\torg.xerial.snappy#snappy-java;1.0.5 from central in [default]\n",
            "\t:: evicted modules:\n",
            "\torg.apache.hadoop#hadoop-annotations;2.10.2 by [org.apache.hadoop#hadoop-annotations;3.2.4] in [default]\n",
            "\torg.apache.commons#commons-compress;1.4.1 by [org.apache.commons#commons-compress;1.21] in [default]\n",
            "\torg.tukaani#xz;1.0 transitively in [default]\n",
            "\tcom.google.errorprone#error_prone_annotations;2.2.0 by [com.google.errorprone#error_prone_annotations;2.18.0] in [default]\n",
            "\tcommons-logging#commons-logging;1.1.3 by [commons-logging#commons-logging;1.2] in [default]\n",
            "\t---------------------------------------------------------------------\n",
            "\t|                  |            modules            ||   artifacts   |\n",
            "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
            "\t---------------------------------------------------------------------\n",
            "\t|      default     |  133  |   0   |   0   |   5   ||  128  |   0   |\n",
            "\t---------------------------------------------------------------------\n",
            ":: retrieving :: org.apache.spark#spark-submit-parent-f9cdd4e1-cb3b-4295-9233-109f0610d892\n",
            "\tconfs: [default]\n",
            "\t0 artifacts copied, 128 already retrieved (0kB/30ms)\n",
            "24/09/24 12:02:20 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
            "Setting default log level to \"WARN\".\n",
            "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Start Spark Session with HBase connector\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"HBase-PySpark-Connection\") \\\n",
        "    .config(\"spark.jars.packages\", \"org.apache.hbase.connectors.spark:hbase-spark:1.0.1\") \\\n",
        "    .getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://p136-n38.kthopen.kth.se:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.4.3</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>HBase-PySpark-Connection</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ],
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x72c28cbe3dd0>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "ename": "Py4JJavaError",
          "evalue": "An error occurred while calling o35.load.\n: org.apache.spark.SparkClassNotFoundException: [DATA_SOURCE_NOT_FOUND] Failed to find the data source: org.apache.hbase.connectors.spark. Please find packages at `https://spark.apache.org/third-party-projects.html`.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.dataSourceNotFoundError(QueryExecutionErrors.scala:738)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:647)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:697)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:208)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.lang.ClassNotFoundException: org.apache.hbase.connectors.spark.DefaultSource\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:594)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:633)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:633)\n\tat scala.util.Failure.orElse(Try.scala:224)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:633)\n\t... 15 more\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43morg.apache.hbase.connectors.spark\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhbase.table.name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mOBIS\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m----> 4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m df\u001b[38;5;241m.\u001b[39mshow()\n",
            "File \u001b[0;32m/opt/spark/python/pyspark/sql/readwriter.py:307\u001b[0m, in \u001b[0;36mDataFrameReader.load\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    305\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jreader\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spark\u001b[38;5;241m.\u001b[39m_sc\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoSeq(path)))\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 307\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
            "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
            "File \u001b[0;32m/opt/spark/python/pyspark/errors/exceptions/captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    171\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
            "File \u001b[0;32m/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o35.load.\n: org.apache.spark.SparkClassNotFoundException: [DATA_SOURCE_NOT_FOUND] Failed to find the data source: org.apache.hbase.connectors.spark. Please find packages at `https://spark.apache.org/third-party-projects.html`.\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.dataSourceNotFoundError(QueryExecutionErrors.scala:738)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:647)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSourceV2(DataSource.scala:697)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:208)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:172)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\nCaused by: java.lang.ClassNotFoundException: org.apache.hbase.connectors.spark.DefaultSource\n\tat java.base/java.net.URLClassLoader.findClass(URLClassLoader.java:476)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:594)\n\tat java.base/java.lang.ClassLoader.loadClass(ClassLoader.java:527)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$5(DataSource.scala:633)\n\tat scala.util.Try$.apply(Try.scala:213)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$lookupDataSource$4(DataSource.scala:633)\n\tat scala.util.Failure.orElse(Try.scala:224)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.lookupDataSource(DataSource.scala:633)\n\t... 15 more\n"
          ]
        }
      ],
      "source": [
        "df = spark.read \\\n",
        "    .format(\"org.apache.hbase.connectors.spark\") \\\n",
        "    .option(\"hbase.table.name\", \"OBIS\") \\\n",
        "    .load()\n",
        "\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "spark.stop()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ch4EE5AUmkZh",
        "outputId": "caa8717d-3603-4834-b9ed-9ccd6d8c4ef1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "stopping hbase............\n"
          ]
        }
      ],
      "source": [
        "#Stop HBase\n",
        "!/opt/hbase/bin/stop-hbase.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7LSCI-lmp3U",
        "outputId": "5173776e-1205-4bde-d9ab-c17d74d3fbff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "387684 Jps\n",
            "385555 SparkSubmit\n"
          ]
        }
      ],
      "source": [
        "!jps"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
